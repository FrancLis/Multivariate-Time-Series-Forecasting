{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3_Linear_Regression_Analysis.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPyu+FusvN7QcJ3XiO/kkp5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FrancLis/Multivariate-Time-Series-Forecasting/blob/main/3_Linear_Regression_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Linear Regression Analysis"
      ],
      "metadata": {
        "id": "_L5SWmDqvusN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A linear regression analysis has been tried to observe the behaviour of the data"
      ],
      "metadata": {
        "id": "Bv3KrJUI_8r_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import sys\n",
        "import statsmodels\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from statsmodels.compat import lzip\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.formula.api import ols\n",
        "import statsmodels.formula.api as smf\n",
        "import statsmodels.stats.api as sms\n",
        "from statsmodels.compat import lzip\n",
        "from scipy import stats\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn"
      ],
      "metadata": {
        "id": "erhcfuTzncQi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7f31854-cb48-4fcc-c542-f4919f156e10"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.style.use('seaborn')"
      ],
      "metadata": {
        "id": "TDdciX4dMqCu"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file = r\"/content/PG.csv\"\n",
        "df = pd.read_csv(file, parse_dates=['Date'], index_col='Date')\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "sROHI1evLEnq",
        "outputId": "086f4b05-5a99-42a1-9d4a-6fe2b0907644"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  Open        High         Low       Close   Adj Close  \\\n",
              "Date                                                                     \n",
              "1970-01-02    1.710938    1.722656    1.708984    1.718750    0.399508   \n",
              "1970-01-05    1.718750    1.730469    1.708984    1.726563    0.401324   \n",
              "1970-01-06    1.722656    1.722656    1.707031    1.718750    0.399508   \n",
              "1970-01-07    1.722656    1.750000    1.722656    1.746094    0.405864   \n",
              "1970-01-08    1.746094    1.773438    1.742188    1.765625    0.410404   \n",
              "...                ...         ...         ...         ...         ...   \n",
              "2022-02-03  161.979996  164.979996  161.619995  164.139999  164.139999   \n",
              "2022-02-04  163.130005  164.490005  161.410004  161.529999  161.529999   \n",
              "2022-02-07  161.869995  162.259995  159.669998  160.320007  160.320007   \n",
              "2022-02-08  161.119995  161.270004  159.649994  159.960007  159.960007   \n",
              "2022-02-09  160.360001  160.639999  159.270004  159.600006  159.600006   \n",
              "\n",
              "              Volume  \n",
              "Date                  \n",
              "1970-01-02    832000  \n",
              "1970-01-05    518400  \n",
              "1970-01-06    480000  \n",
              "1970-01-07    710400  \n",
              "1970-01-08    531200  \n",
              "...              ...  \n",
              "2022-02-03  10474500  \n",
              "2022-02-04   8959900  \n",
              "2022-02-07   6430500  \n",
              "2022-02-08   5048700  \n",
              "2022-02-09   8077400  \n",
              "\n",
              "[13145 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9d20eba0-23c0-4176-bbb4-42e36dc3a4ed\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1970-01-02</th>\n",
              "      <td>1.710938</td>\n",
              "      <td>1.722656</td>\n",
              "      <td>1.708984</td>\n",
              "      <td>1.718750</td>\n",
              "      <td>0.399508</td>\n",
              "      <td>832000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1970-01-05</th>\n",
              "      <td>1.718750</td>\n",
              "      <td>1.730469</td>\n",
              "      <td>1.708984</td>\n",
              "      <td>1.726563</td>\n",
              "      <td>0.401324</td>\n",
              "      <td>518400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1970-01-06</th>\n",
              "      <td>1.722656</td>\n",
              "      <td>1.722656</td>\n",
              "      <td>1.707031</td>\n",
              "      <td>1.718750</td>\n",
              "      <td>0.399508</td>\n",
              "      <td>480000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1970-01-07</th>\n",
              "      <td>1.722656</td>\n",
              "      <td>1.750000</td>\n",
              "      <td>1.722656</td>\n",
              "      <td>1.746094</td>\n",
              "      <td>0.405864</td>\n",
              "      <td>710400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1970-01-08</th>\n",
              "      <td>1.746094</td>\n",
              "      <td>1.773438</td>\n",
              "      <td>1.742188</td>\n",
              "      <td>1.765625</td>\n",
              "      <td>0.410404</td>\n",
              "      <td>531200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-02-03</th>\n",
              "      <td>161.979996</td>\n",
              "      <td>164.979996</td>\n",
              "      <td>161.619995</td>\n",
              "      <td>164.139999</td>\n",
              "      <td>164.139999</td>\n",
              "      <td>10474500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-02-04</th>\n",
              "      <td>163.130005</td>\n",
              "      <td>164.490005</td>\n",
              "      <td>161.410004</td>\n",
              "      <td>161.529999</td>\n",
              "      <td>161.529999</td>\n",
              "      <td>8959900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-02-07</th>\n",
              "      <td>161.869995</td>\n",
              "      <td>162.259995</td>\n",
              "      <td>159.669998</td>\n",
              "      <td>160.320007</td>\n",
              "      <td>160.320007</td>\n",
              "      <td>6430500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-02-08</th>\n",
              "      <td>161.119995</td>\n",
              "      <td>161.270004</td>\n",
              "      <td>159.649994</td>\n",
              "      <td>159.960007</td>\n",
              "      <td>159.960007</td>\n",
              "      <td>5048700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-02-09</th>\n",
              "      <td>160.360001</td>\n",
              "      <td>160.639999</td>\n",
              "      <td>159.270004</td>\n",
              "      <td>159.600006</td>\n",
              "      <td>159.600006</td>\n",
              "      <td>8077400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>13145 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9d20eba0-23c0-4176-bbb4-42e36dc3a4ed')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9d20eba0-23c0-4176-bbb4-42e36dc3a4ed button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9d20eba0-23c0-4176-bbb4-42e36dc3a4ed');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.rename(columns={\"Adj Close\": \"AdjClose\"})"
      ],
      "metadata": {
        "id": "TsV7xRewn1vr"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Close_shifted'] = df['Close'].shift(periods=1)\n",
        "df = df.dropna()\n",
        "df"
      ],
      "metadata": {
        "id": "5Xk6kfeoyYY3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "outputId": "b2d01626-c436-4d73-eea6-0b9cf85ec262"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  Open        High         Low       Close    AdjClose  \\\n",
              "Date                                                                     \n",
              "1970-01-05    1.718750    1.730469    1.708984    1.726563    0.401324   \n",
              "1970-01-06    1.722656    1.722656    1.707031    1.718750    0.399508   \n",
              "1970-01-07    1.722656    1.750000    1.722656    1.746094    0.405864   \n",
              "1970-01-08    1.746094    1.773438    1.742188    1.765625    0.410404   \n",
              "1970-01-09    1.765625    1.765625    1.753906    1.761719    0.409496   \n",
              "...                ...         ...         ...         ...         ...   \n",
              "2022-02-03  161.979996  164.979996  161.619995  164.139999  164.139999   \n",
              "2022-02-04  163.130005  164.490005  161.410004  161.529999  161.529999   \n",
              "2022-02-07  161.869995  162.259995  159.669998  160.320007  160.320007   \n",
              "2022-02-08  161.119995  161.270004  159.649994  159.960007  159.960007   \n",
              "2022-02-09  160.360001  160.639999  159.270004  159.600006  159.600006   \n",
              "\n",
              "              Volume  Close_shifted  \n",
              "Date                                 \n",
              "1970-01-05    518400       1.718750  \n",
              "1970-01-06    480000       1.726563  \n",
              "1970-01-07    710400       1.718750  \n",
              "1970-01-08    531200       1.746094  \n",
              "1970-01-09    262400       1.765625  \n",
              "...              ...            ...  \n",
              "2022-02-03  10474500     162.600006  \n",
              "2022-02-04   8959900     164.139999  \n",
              "2022-02-07   6430500     161.529999  \n",
              "2022-02-08   5048700     160.320007  \n",
              "2022-02-09   8077400     159.960007  \n",
              "\n",
              "[13144 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-09a1c7eb-09c7-4fdf-86f6-04fb6136dd85\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>AdjClose</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Close_shifted</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1970-01-05</th>\n",
              "      <td>1.718750</td>\n",
              "      <td>1.730469</td>\n",
              "      <td>1.708984</td>\n",
              "      <td>1.726563</td>\n",
              "      <td>0.401324</td>\n",
              "      <td>518400</td>\n",
              "      <td>1.718750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1970-01-06</th>\n",
              "      <td>1.722656</td>\n",
              "      <td>1.722656</td>\n",
              "      <td>1.707031</td>\n",
              "      <td>1.718750</td>\n",
              "      <td>0.399508</td>\n",
              "      <td>480000</td>\n",
              "      <td>1.726563</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1970-01-07</th>\n",
              "      <td>1.722656</td>\n",
              "      <td>1.750000</td>\n",
              "      <td>1.722656</td>\n",
              "      <td>1.746094</td>\n",
              "      <td>0.405864</td>\n",
              "      <td>710400</td>\n",
              "      <td>1.718750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1970-01-08</th>\n",
              "      <td>1.746094</td>\n",
              "      <td>1.773438</td>\n",
              "      <td>1.742188</td>\n",
              "      <td>1.765625</td>\n",
              "      <td>0.410404</td>\n",
              "      <td>531200</td>\n",
              "      <td>1.746094</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1970-01-09</th>\n",
              "      <td>1.765625</td>\n",
              "      <td>1.765625</td>\n",
              "      <td>1.753906</td>\n",
              "      <td>1.761719</td>\n",
              "      <td>0.409496</td>\n",
              "      <td>262400</td>\n",
              "      <td>1.765625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-02-03</th>\n",
              "      <td>161.979996</td>\n",
              "      <td>164.979996</td>\n",
              "      <td>161.619995</td>\n",
              "      <td>164.139999</td>\n",
              "      <td>164.139999</td>\n",
              "      <td>10474500</td>\n",
              "      <td>162.600006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-02-04</th>\n",
              "      <td>163.130005</td>\n",
              "      <td>164.490005</td>\n",
              "      <td>161.410004</td>\n",
              "      <td>161.529999</td>\n",
              "      <td>161.529999</td>\n",
              "      <td>8959900</td>\n",
              "      <td>164.139999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-02-07</th>\n",
              "      <td>161.869995</td>\n",
              "      <td>162.259995</td>\n",
              "      <td>159.669998</td>\n",
              "      <td>160.320007</td>\n",
              "      <td>160.320007</td>\n",
              "      <td>6430500</td>\n",
              "      <td>161.529999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-02-08</th>\n",
              "      <td>161.119995</td>\n",
              "      <td>161.270004</td>\n",
              "      <td>159.649994</td>\n",
              "      <td>159.960007</td>\n",
              "      <td>159.960007</td>\n",
              "      <td>5048700</td>\n",
              "      <td>160.320007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-02-09</th>\n",
              "      <td>160.360001</td>\n",
              "      <td>160.639999</td>\n",
              "      <td>159.270004</td>\n",
              "      <td>159.600006</td>\n",
              "      <td>159.600006</td>\n",
              "      <td>8077400</td>\n",
              "      <td>159.960007</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>13144 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-09a1c7eb-09c7-4fdf-86f6-04fb6136dd85')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-09a1c7eb-09c7-4fdf-86f6-04fb6136dd85 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-09a1c7eb-09c7-4fdf-86f6-04fb6136dd85');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import PowerTransformer\n",
        "\n",
        "pt = PowerTransformer(method='box-cox')\n",
        "df_transformed = pt.fit_transform(df)"
      ],
      "metadata": {
        "id": "PbERe7XgHIDQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_transformed = pd.DataFrame(df_transformed, index=df.index, columns=[['Open','High','Low','Close','AdjClose','Volume', 'Close_shifted']])"
      ],
      "metadata": {
        "id": "C5-VM0SRoyZ8"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_transformed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "j49BYhazM47y",
        "outputId": "a9e5c3a0-8210-4680-fa55-3ea8975b3e6f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                Open      High       Low     Close  AdjClose    Volume  \\\n",
              "Date                                                                     \n",
              "1970-01-05 -1.478813 -1.479292 -1.477902 -1.476151 -1.535179 -1.705593   \n",
              "1970-01-06 -1.477516 -1.481872 -1.478557 -1.478741 -1.537210 -1.749494   \n",
              "1970-01-07 -1.477516 -1.472889 -1.473339 -1.469724 -1.530138 -1.515211   \n",
              "1970-01-08 -1.469790 -1.465292 -1.466877 -1.463362 -1.525150 -1.691472   \n",
              "1970-01-09 -1.463424 -1.467814 -1.463031 -1.464629 -1.526143 -2.061789   \n",
              "...              ...       ...       ...       ...       ...       ...   \n",
              "2022-02-03  1.713991  1.723623  1.717458  1.724784  1.755645  1.070828   \n",
              "2022-02-04  1.720021  1.721081  1.716352  1.711116  1.745069  0.858989   \n",
              "2022-02-07  1.713412  1.709428  1.707139  1.704712  1.740111  0.439885   \n",
              "2022-02-08  1.709455  1.704207  1.707033  1.702797  1.738630  0.158829   \n",
              "2022-02-09  1.705429  1.700870  1.705008  1.700879  1.737145  0.723594   \n",
              "\n",
              "           Close_shifted  \n",
              "Date                      \n",
              "1970-01-05     -1.478591  \n",
              "1970-01-06     -1.476001  \n",
              "1970-01-07     -1.478591  \n",
              "1970-01-08     -1.469573  \n",
              "1970-01-09     -1.463209  \n",
              "...                  ...  \n",
              "2022-02-03      1.716941  \n",
              "2022-02-04      1.724981  \n",
              "2022-02-07      1.711314  \n",
              "2022-02-08      1.704910  \n",
              "2022-02-09      1.702997  \n",
              "\n",
              "[13144 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0901229a-5771-4ce1-b739-6ae329461837\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>AdjClose</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Close_shifted</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1970-01-05</th>\n",
              "      <td>-1.478813</td>\n",
              "      <td>-1.479292</td>\n",
              "      <td>-1.477902</td>\n",
              "      <td>-1.476151</td>\n",
              "      <td>-1.535179</td>\n",
              "      <td>-1.705593</td>\n",
              "      <td>-1.478591</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1970-01-06</th>\n",
              "      <td>-1.477516</td>\n",
              "      <td>-1.481872</td>\n",
              "      <td>-1.478557</td>\n",
              "      <td>-1.478741</td>\n",
              "      <td>-1.537210</td>\n",
              "      <td>-1.749494</td>\n",
              "      <td>-1.476001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1970-01-07</th>\n",
              "      <td>-1.477516</td>\n",
              "      <td>-1.472889</td>\n",
              "      <td>-1.473339</td>\n",
              "      <td>-1.469724</td>\n",
              "      <td>-1.530138</td>\n",
              "      <td>-1.515211</td>\n",
              "      <td>-1.478591</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1970-01-08</th>\n",
              "      <td>-1.469790</td>\n",
              "      <td>-1.465292</td>\n",
              "      <td>-1.466877</td>\n",
              "      <td>-1.463362</td>\n",
              "      <td>-1.525150</td>\n",
              "      <td>-1.691472</td>\n",
              "      <td>-1.469573</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1970-01-09</th>\n",
              "      <td>-1.463424</td>\n",
              "      <td>-1.467814</td>\n",
              "      <td>-1.463031</td>\n",
              "      <td>-1.464629</td>\n",
              "      <td>-1.526143</td>\n",
              "      <td>-2.061789</td>\n",
              "      <td>-1.463209</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-02-03</th>\n",
              "      <td>1.713991</td>\n",
              "      <td>1.723623</td>\n",
              "      <td>1.717458</td>\n",
              "      <td>1.724784</td>\n",
              "      <td>1.755645</td>\n",
              "      <td>1.070828</td>\n",
              "      <td>1.716941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-02-04</th>\n",
              "      <td>1.720021</td>\n",
              "      <td>1.721081</td>\n",
              "      <td>1.716352</td>\n",
              "      <td>1.711116</td>\n",
              "      <td>1.745069</td>\n",
              "      <td>0.858989</td>\n",
              "      <td>1.724981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-02-07</th>\n",
              "      <td>1.713412</td>\n",
              "      <td>1.709428</td>\n",
              "      <td>1.707139</td>\n",
              "      <td>1.704712</td>\n",
              "      <td>1.740111</td>\n",
              "      <td>0.439885</td>\n",
              "      <td>1.711314</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-02-08</th>\n",
              "      <td>1.709455</td>\n",
              "      <td>1.704207</td>\n",
              "      <td>1.707033</td>\n",
              "      <td>1.702797</td>\n",
              "      <td>1.738630</td>\n",
              "      <td>0.158829</td>\n",
              "      <td>1.704910</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-02-09</th>\n",
              "      <td>1.705429</td>\n",
              "      <td>1.700870</td>\n",
              "      <td>1.705008</td>\n",
              "      <td>1.700879</td>\n",
              "      <td>1.737145</td>\n",
              "      <td>0.723594</td>\n",
              "      <td>1.702997</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>13144 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0901229a-5771-4ce1-b739-6ae329461837')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0901229a-5771-4ce1-b739-6ae329461837 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0901229a-5771-4ce1-b739-6ae329461837');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OLS\n",
        "\n"
      ],
      "metadata": {
        "id": "vgLRwwEOgXYK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**OLS** is a common technique used in analyzing linear regression. In brief, it compares the difference between individual points in your data set and the predicted best fit line to measure the amount of error produced. The smf.ols() function requires two inputs, the formula for producing the best fit line, and the dataset.The formula is provided as a string, in the following form:\n",
        "\n",
        "***‘dependent variable ~ list of independent variables separated by the + symbol’*** \n",
        "\n",
        "In plain terms, the dependent variable is the factor you are trying to predict, and on the other side of the formula are the variables you are using to predict."
      ],
      "metadata": {
        "id": "YZt4MT-FKbse"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mod = smf.ols(\"Close_shifted ~ Open + High + Low\t+ Close + AdjClose + Volume\", data=df_transformed)\n",
        "reg = mod.fit()\n",
        "reg.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 549
        },
        "id": "4hIIFnZo1bPS",
        "outputId": "bca982f9-1dab-4fc0-a378-fb21bf4451f1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<class 'statsmodels.iolib.summary.Summary'>\n",
              "\"\"\"\n",
              "                            OLS Regression Results                            \n",
              "==============================================================================\n",
              "Dep. Variable:          Close_shifted   R-squared:                       1.000\n",
              "Model:                            OLS   Adj. R-squared:                  1.000\n",
              "Method:                 Least Squares   F-statistic:                 7.865e+07\n",
              "Date:                Wed, 27 Apr 2022   Prob (F-statistic):               0.00\n",
              "Time:                        18:06:24   Log-Likelihood:                 50284.\n",
              "No. Observations:               13144   AIC:                        -1.006e+05\n",
              "Df Residuals:                   13137   BIC:                        -1.005e+05\n",
              "Df Model:                           6                                         \n",
              "Covariance Type:            nonrobust                                         \n",
              "==============================================================================\n",
              "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
              "------------------------------------------------------------------------------\n",
              "Intercept    2.22e-16    4.6e-05   4.82e-12      1.000   -9.02e-05    9.02e-05\n",
              "Open           0.7397      0.010     75.852      0.000       0.721       0.759\n",
              "High           0.4157      0.011     36.531      0.000       0.393       0.438\n",
              "Low            0.1179      0.009     12.641      0.000       0.100       0.136\n",
              "Close         -0.2739      0.010    -26.285      0.000      -0.294      -0.253\n",
              "AdjClose       0.0008      0.001      0.972      0.331      -0.001       0.002\n",
              "Volume        -0.0003      8e-05     -3.989      0.000      -0.000      -0.000\n",
              "==============================================================================\n",
              "Omnibus:                    18496.290   Durbin-Watson:                   2.033\n",
              "Prob(Omnibus):                  0.000   Jarque-Bera (JB):        110105779.674\n",
              "Skew:                           7.156   Prob(JB):                         0.00\n",
              "Kurtosis:                     451.152   Cond. No.                         872.\n",
              "==============================================================================\n",
              "\n",
              "Warnings:\n",
              "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
              "\"\"\""
            ],
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>OLS Regression Results</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>      <td>Close_shifted</td>  <th>  R-squared:         </th>  <td>   1.000</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   1.000</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>7.865e+07</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>             <td>Wed, 27 Apr 2022</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>                 <td>18:06:24</td>     <th>  Log-Likelihood:    </th>  <td>  50284.</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>No. Observations:</th>      <td> 13144</td>      <th>  AIC:               </th> <td>-1.006e+05</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Residuals:</th>          <td> 13137</td>      <th>  BIC:               </th> <td>-1.005e+05</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Model:</th>              <td>     6</td>      <th>                     </th>      <td> </td>    \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>    \n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Intercept</th> <td>  2.22e-16</td> <td>  4.6e-05</td> <td> 4.82e-12</td> <td> 1.000</td> <td>-9.02e-05</td> <td> 9.02e-05</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Open</th>      <td>    0.7397</td> <td>    0.010</td> <td>   75.852</td> <td> 0.000</td> <td>    0.721</td> <td>    0.759</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>High</th>      <td>    0.4157</td> <td>    0.011</td> <td>   36.531</td> <td> 0.000</td> <td>    0.393</td> <td>    0.438</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Low</th>       <td>    0.1179</td> <td>    0.009</td> <td>   12.641</td> <td> 0.000</td> <td>    0.100</td> <td>    0.136</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Close</th>     <td>   -0.2739</td> <td>    0.010</td> <td>  -26.285</td> <td> 0.000</td> <td>   -0.294</td> <td>   -0.253</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>AdjClose</th>  <td>    0.0008</td> <td>    0.001</td> <td>    0.972</td> <td> 0.331</td> <td>   -0.001</td> <td>    0.002</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Volume</th>    <td>   -0.0003</td> <td>    8e-05</td> <td>   -3.989</td> <td> 0.000</td> <td>   -0.000</td> <td>   -0.000</td>\n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "  <th>Omnibus:</th>       <td>18496.290</td> <th>  Durbin-Watson:     </th>   <td>   2.033</td>   \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>110105779.674</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Skew:</th>           <td> 7.156</td>   <th>  Prob(JB):          </th>   <td>    0.00</td>   \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Kurtosis:</th>       <td>451.152</td>  <th>  Cond. No.          </th>   <td>    872.</td>   \n",
              "</tr>\n",
              "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Summary explanation**"
      ],
      "metadata": {
        "id": "-5M_v-QpKi8w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The top of our summary starts by giving us a few details we already know. \n",
        "\n",
        "\n",
        "**Df Residuals** \n",
        "\n",
        "is another name for our Degrees of Freedom in our mode.\n",
        "This is calculated in the form of ‘n-k-1’ or ‘number of observations-number of predicting variables-1.’ \n",
        "\n",
        "**Df Model** \n",
        "\n",
        "numbers our predicting variables. If you’re wondering why we only entered 3 predicting variables into the formula but both Df Residuals and Model are saying there are 6, we’ll get into this later. \n",
        "\n",
        "**Covariance Type**\n",
        "\n",
        "Covariance is a measure of how two variables are linked in a positive or negative manner, and a robust covariance is one that is calculated in a way to minimize or eliminate variables, which is not the case here.\n",
        "\n",
        "**R-squared** \n",
        "\n",
        "is possibly the most important measurement produced by this summary. R-squared is the measurement of how much of the independent variable is explained by changes in our dependent variables. \n",
        "\n",
        "**Adjusted R-squared**\n",
        "\n",
        "R-squared value will never go down with additional variables, only equal or higher. Therefore, your model could look more accurate with multiple variables even if they are poorly contributing. The adjusted R-squared penalizes the R-squared formula based on the number of variables, therefore a lower adjusted score may be telling you some variables are not contributing to your model’s R-squared properly.\n",
        "\n",
        "**F-statistic**\n",
        "\n",
        "In linear regression is comparing your produced linear model for your variables against a model that replaces your variables’ effect to 0, to find out if your group of variables are statistically significant. To interpret this number correctly, using a chosen alpha value and an F-table is necessary. \n",
        "\n",
        "**Prob (F-Statistic)** \n",
        "\n",
        "uses this number to tell you the accuracy of the null hypothesis, or whether it is accurate that your variables’ effect is 0. In this case, it is telling us 0% chance of this. \n",
        "\n",
        "**Log-likelihood** \n",
        "\n",
        "is a numerical signifier of the likelihood that your produced model produced the given data. It is used to compare coefficient values for each variable in the process of creating the model.\n",
        "\n",
        "**AIC** - **BIC** \n",
        "\n",
        "both used to compare the efficacy of models in the process of linear regression, using a penalty system for measuring multiple variables. These numbers are used for feature selection of variables.\n",
        "\n",
        "**Intercept**\n",
        "\n",
        "is the result of our model if all variables were tuned to 0. In the classic ‘y = mx+b’ linear formula, it is our b, a constant added to explain a starting value for our line.\n",
        "\n",
        "**Coefficient** \n",
        "\n",
        "For our intercept, it is the value of the intercept. For each variable, it is the measurement of how change in that variable affects the independent variable. It is the ‘m’ in ‘y = mx + b’ One unit of change in the dependent variable will affect the variable’s coefficient’s worth of change in the independent variable. If the coefficient is negative, they have an inverse relationship. As one rises, the other falls.\n",
        "\n",
        "**Std error** \n",
        "\n",
        "is an estimate of the standard deviation of the coefficient, a measurement of the amount of variation in the coefficient throughout its data points. The t is related and is a measurement of the precision with which the coefficient was measured. A low std error compared to a high coefficient produces a high **t statistic**, which signifies a high significance for your coefficient.\n",
        "\n",
        "**P>|t|**\n",
        "\n",
        " is one of the most important statistics in the summary. It uses the t statistic to produce the **p value**, a measurement of how likely your coefficient is measured through our model by chance. The p value of 0.378 for Wealth is saying there is a 37.8% chance the Wealth variable has no affect on the dependent variable, Lottery, and our results are produced by chance. Proper model analysis will compare the p value to a previously established alpha value, or a threshold with which we can apply significance to our coefficient. A common alpha is 0.05, which few of our variables pass in this instance.\n",
        "[0.025 and 0.975] are both measurements of values of our coefficients within 95% of our data, or within two standard deviations. Outside of these values can generally be considered outliers.\n",
        "\n",
        "**Omnibus** \n",
        "\n",
        "describes the normalcy of the distribution of our residuals using skew and kurtosis as measurements. A 0 would indicate perfect normalcy. \n",
        "\n",
        "**Prob(Omnibus)** \n",
        "\n",
        "is a statistical test measuring the probability the residuals are normally distributed. A 1 would indicate perfectly normal distribution.\n",
        "\n",
        "**Skew**\n",
        "\n",
        "is a measurement of symmetry in our data, with 0 being perfect symmetry.\n",
        "\n",
        "**Kurtosis**\n",
        "\n",
        " measures the peakiness of our data, or its concentration around 0 in a normal curve. Higher kurtosis implies fewer outliers.\n",
        "\n",
        "**Durbin-Watson**\n",
        "\n",
        " is a measurement of homoscedasticity, or an even distribution of errors throughout our data. Heteroscedasticity would imply an uneven distribution, for example as the data point grows higher the relative error grows higher. Ideal homoscedasticity will lie between 1 and 2. If Durbin–Watson is less than 1.0, there may be cause for concern. Small values of d indicate successive error terms are positively correlated. If d > 2, successive error terms are negatively correlated. If there is no autocorrelation, the Durbin-Watson distribution is symmetric around 2.\n",
        "\n",
        "\n",
        "**Jarque-Bera (JB)** and **Prob(JB)**\n",
        "\n",
        "are alternate methods of measuring the same value as Omnibus and Prob(Omnibus) using skewness and kurtosis. We use these values to confirm each other. *Given the statistical value of 2.16, the test provides evidence that there is no serial correlation present meaning the residual error terms are uncorrelated and are independent.*\n",
        "\n",
        "**Condition number**\n",
        "\n",
        " is a measurement of the sensitivity of our model as compared to the size of changes in the data it is analyzing. Multicollinearity is strongly implied by a high condition number. Multicollinearity a term to describe two or more independent variables that are strongly related to each other and are falsely affecting our predicted variable by redundancy.\n",
        "\n",
        "Our definitions barely scratch the surface of any one of these topics. Independent research is strongly encouraged for an understanding of these terms and how they relate to one another\n",
        "\n",
        "\n",
        "---------------------------------------------------\n",
        "\n",
        "\n",
        "From the summary emerges that the coefficients are statistically significant. The residuals are not normally distributed. There is skewness as well as the kurtosis is greater than zero, then the distribution has heavier tails and is called a leptokurtic distribution.\n"
      ],
      "metadata": {
        "id": "3wOICTX4g3fV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from statsmodels.tools.tools import maybe_unwrap_results\n",
        "from statsmodels.graphics.gofplots import ProbPlot\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "import matplotlib.pyplot as plt\n",
        "from typing import Type\n",
        "\n",
        "style_talk = 'seaborn-talk'   \n",
        "\n",
        "class Linear_Reg_Diagnostic():\n",
        "    \"\"\"\n",
        "    Diagnostic plots to identify potential problems in a linear regression fit.\n",
        "    Mainly,\n",
        "        a. non-linearity of data\n",
        "        b. Correlation of error terms\n",
        "        c. non-constant variance\n",
        "        d. outliers\n",
        "        e. high-leverage points\n",
        "        f. collinearity\n",
        "\n",
        "    Author:\n",
        "        Prajwal Kafle (p33ajkafle@gmail.com, where 3 = r)\n",
        "        Does not come with any sort of warranty.\n",
        "        Please test the code one your end before using.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 results: Type[statsmodels.regression.linear_model.RegressionResultsWrapper]) -> None:\n",
        "        \"\"\"\n",
        "        For a linear regression model, generates following diagnostic plots:\n",
        "\n",
        "        a. residual\n",
        "        b. qq\n",
        "        c. scale location and\n",
        "        d. leverage\n",
        "\n",
        "        and a table\n",
        "\n",
        "        e. vif\n",
        "\n",
        "        Args:\n",
        "            results (Type[statsmodels.regression.linear_model.RegressionResultsWrapper]):\n",
        "                must be instance of statsmodels.regression.linear_model object\n",
        "\n",
        "        Raises:\n",
        "            TypeError: if instance does not belong to above object\n",
        "\n",
        "        Example:\n",
        "        >>> import numpy as np\n",
        "        >>> import pandas as pd\n",
        "        >>> import statsmodels.formula.api as smf\n",
        "        >>> x = np.linspace(-np.pi, np.pi, 100)\n",
        "        >>> y = 3*x + 8 + np.random.normal(0,1, 100)\n",
        "        >>> df = pd.DataFrame({'x':x, 'y':y})\n",
        "        >>> res = smf.ols(formula= \"y ~ x\", data=df).fit()\n",
        "        >>> cls = Linear_Reg_Diagnostic(res)\n",
        "        >>> cls(plot_context=\"seaborn-paper\")\n",
        "\n",
        "        In case you do not need all plots you can also independently make an individual plot/table\n",
        "        in following ways\n",
        "\n",
        "        >>> cls = Linear_Reg_Diagnostic(res)\n",
        "        >>> cls.residual_plot()\n",
        "        >>> cls.qq_plot()\n",
        "        >>> cls.scale_location_plot()\n",
        "        >>> cls.leverage_plot()\n",
        "        >>> cls.vif_table()\n",
        "        \"\"\"\n",
        "\n",
        "        if isinstance(results, statsmodels.regression.linear_model.RegressionResultsWrapper) is False:\n",
        "            raise TypeError(\"result must be instance of statsmodels.regression.linear_model.RegressionResultsWrapper object\")\n",
        "\n",
        "        self.results = maybe_unwrap_results(results)\n",
        "\n",
        "        self.y_true = self.results.model.endog\n",
        "        self.y_predict = self.results.fittedvalues\n",
        "        self.xvar = self.results.model.exog\n",
        "        self.xvar_names = self.results.model.exog_names\n",
        "\n",
        "        self.residual = np.array(self.results.resid)\n",
        "        influence = self.results.get_influence()\n",
        "        self.residual_norm = influence.resid_studentized_internal\n",
        "        self.leverage = influence.hat_matrix_diag\n",
        "        self.cooks_distance = influence.cooks_distance[0]\n",
        "        self.nparams = len(self.results.params)\n",
        "\n",
        "    def __call__(self, plot_context='seaborn-paper'):\n",
        "        # print(plt.style.available)\n",
        "        with plt.style.context(plot_context):\n",
        "            fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(10,10))\n",
        "            self.residual_plot(ax=ax[0,0])\n",
        "            self.qq_plot(ax=ax[0,1])\n",
        "            self.scale_location_plot(ax=ax[1,0])\n",
        "            self.leverage_plot(ax=ax[1,1])\n",
        "            plt.show()\n",
        "\n",
        "        self.vif_table()\n",
        "        return fig, ax\n",
        "\n",
        "\n",
        "    def residual_plot(self, ax=None):\n",
        "        \"\"\"\n",
        "        Residual vs Fitted Plot\n",
        "\n",
        "        Graphical tool to identify non-linearity.\n",
        "        (Roughly) Horizontal red line is an indicator that the residual has a linear pattern\n",
        "        \"\"\"\n",
        "        if ax is None:\n",
        "            fig, ax = plt.subplots()\n",
        "\n",
        "        sns.residplot(\n",
        "            x=self.y_predict,\n",
        "            y=self.residual,\n",
        "            lowess=True,\n",
        "            scatter_kws={'alpha': 0.5},\n",
        "            line_kws={'color': 'red', 'lw': 1, 'alpha': 0.8},\n",
        "            ax=ax)\n",
        "\n",
        "        # annotations\n",
        "        residual_abs = np.abs(self.residual)\n",
        "        abs_resid = np.flip(np.sort(residual_abs))\n",
        "        abs_resid_top_3 = abs_resid[:3]\n",
        "        for i, _ in enumerate(abs_resid_top_3):\n",
        "            ax.annotate(\n",
        "                i,\n",
        "                xy=(self.y_predict[i], self.residual[i]),\n",
        "                color='C3')\n",
        "\n",
        "        ax.set_title('Residuals vs Fitted', fontweight=\"bold\")\n",
        "        ax.set_xlabel('Fitted values')\n",
        "        ax.set_ylabel('Residuals')\n",
        "        return ax\n",
        "\n",
        "\n",
        "    def qq_plot(self, ax=None):\n",
        "        \"\"\"\n",
        "        Standarized Residual vs Theoretical Quantile plot\n",
        "\n",
        "        Used to visually check if residuals are normally distributed.\n",
        "        Points spread along the diagonal line will suggest so.\n",
        "        \"\"\"\n",
        "        if ax is None:\n",
        "            fig, ax = plt.subplots()\n",
        "\n",
        "        QQ = ProbPlot(self.residual_norm)\n",
        "        QQ.qqplot(line='45', alpha=0.5, lw=1, ax=ax)\n",
        "\n",
        "        # annotations\n",
        "        abs_norm_resid = np.flip(np.argsort(np.abs(self.residual_norm)), 0)\n",
        "        abs_norm_resid_top_3 = abs_norm_resid[:3]\n",
        "        for r, i in enumerate(abs_norm_resid_top_3):\n",
        "            ax.annotate(\n",
        "                i,\n",
        "                xy=(np.flip(QQ.theoretical_quantiles, 0)[r], self.residual_norm[i]),\n",
        "                ha='right', color='C3')\n",
        "\n",
        "        ax.set_title('Normal Q-Q', fontweight=\"bold\")\n",
        "        ax.set_xlabel('Theoretical Quantiles')\n",
        "        ax.set_ylabel('Standardized Residuals')\n",
        "        return ax\n",
        "\n",
        "\n",
        "    def vif_table(self):\n",
        "        \"\"\"\n",
        "        VIF table\n",
        "\n",
        "        VIF, the variance inflation factor, is a measure of multicollinearity.\n",
        "        VIF > 5 for a variable indicates that it is highly collinear with the\n",
        "        other input variables.\n",
        "        \"\"\"\n",
        "        vif_df = pd.DataFrame()\n",
        "        vif_df[\"Features\"] = self.xvar_names\n",
        "        vif_df[\"VIF Factor\"] = [variance_inflation_factor(self.xvar, i) for i in range(self.xvar.shape[1])]\n",
        "\n",
        "        print(vif_df\n",
        "                .sort_values(\"VIF Factor\")\n",
        "                .round(2))"
      ],
      "metadata": {
        "id": "OxVy1uBqmPy0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cls1 = Linear_Reg_Diagnostic(reg)"
      ],
      "metadata": {
        "id": "5MwSGG4H7ELU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Autocorrelation**"
      ],
      "metadata": {
        "id": "e08pJUmKN98-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A Durbin-Watson value greater than 2 suggests that our series has no autocorrelation."
      ],
      "metadata": {
        "id": "xejvF7A5N5Zf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Normality**"
      ],
      "metadata": {
        "id": "cZQtghVROSWB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**It seems that residuals are not so normal**.\n",
        "\n",
        "A Jarque-Bera test has been performed"
      ],
      "metadata": {
        "id": "V5zqTnnEOlj7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "name = ['Jarque-Bera', 'Chi^2 two-tail prob.', 'Skew', 'Kurtosis']\n",
        "test = sms.jarque_bera(reg.resid)\n",
        "lzip(name, test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYZy5sSkXLv0",
        "outputId": "0fe7f468-ebde-4f37-c022-50910707f6fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Jarque-Bera', 119041618.20742248),\n",
              " ('Chi^2 two-tail prob.', 0.0),\n",
              " ('Skew', 6.997238261707266),\n",
              " ('Kurtosis', 494.25260490326525)]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The test is significant; meaning the data violates the assumption of normality of the residuals"
      ],
      "metadata": {
        "id": "vMHSmQrYXw9v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import stats\n",
        "\n",
        "# get values of the residuals\n",
        "residual = reg.resid\n",
        "\n",
        "# run tests and get the p values\n",
        "print('p value of Jarque-Bera test is: ', stats.jarque_bera(residual)[1])\n",
        "print('p value of Shapiro-Wilk test is: ', stats.shapiro(residual)[1])\n",
        "print('p value of Kolmogorov-Smirnov test is: ', stats.kstest(residual, 'norm')[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z6t4R-dsOLRj",
        "outputId": "11dbc27d-fa34-4db6-be16-e730322df046"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p value of Jarque-Bera test is:  0.0\n",
            "p value of Shapiro-Wilk test is:  0.0\n",
            "p value of Kolmogorov-Smirnov test is:  0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scipy/stats/morestats.py:1676: UserWarning: p-value may not be accurate for N > 5000.\n",
            "  warnings.warn(\"p-value may not be accurate for N > 5000.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assuming a significance level of 0.05, all three tests suggest that our series is not normally distributed."
      ],
      "metadata": {
        "id": "nFrJSBDqORTI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cls1.qq_plot();"
      ],
      "metadata": {
        "id": "k139edr-7nCA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "cfeb0c51-11a2-4a9b-e81f-a4acc3b72ce2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This plot reinforce the idea of the statistical tests performed. If the residuals follow a straight line, they are more normally distributed, and if they deviate severely they may not be so normal and there could be a pattern in your data you are missing.\n"
      ],
      "metadata": {
        "id": "N70yixEBvp2T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Assumption of Homoscedasticity**"
      ],
      "metadata": {
        "id": "lMd5OmPIaYrP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For heteroscedasticity, we will use the following tests:\n",
        "\n",
        "\n",
        "Breusch-Pagan test\n",
        "\n",
        "White Test"
      ],
      "metadata": {
        "id": "VX9tNKL_OXlN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.stats.api as sms\n",
        "\n",
        "print('p value of Breusch–Pagan test is: ', sms.het_breuschpagan(reg.resid, reg.model.exog)[1])\n",
        "print('p value of White test is: ', sms.het_white(reg.resid, reg.model.exog)[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "msUgI9SaOXJz",
        "outputId": "2952748c-0748-486f-d1e0-ad663fc23645"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p value of Breusch–Pagan test is:  5.229399285330141e-296\n",
            "p value of White test is:  0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assuming a significance level of 0.05, the two tests suggest that our series is heteroscedastic.\n",
        "\n",
        "Our series is neither homoscedastic nor normally distributed. Lucky for us, unlike OLS, generalized least squares accounts for these residual errors."
      ],
      "metadata": {
        "id": "IXKtF9hgOkKc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Consequences of Heteroscedasticity**\n",
        "\n",
        "The OLS estimators and regression predictions based on them remains unbiased and consistent.\n",
        "The OLS estimators are no longer the BLUE (Best Linear Unbiased Estimators) because they are no longer efficient, so the regression predictions will be inefficient too.\n",
        "\n",
        "Because of the inconsistency of the covariance matrix of the estimated regression coefficients, the tests of hypotheses, (t-test, F-test) are no longer valid.\n",
        "\n",
        "**How to Deal with Heteroscedastic Data**\n",
        "\n",
        "If your data is heteroscedastic, it would be inadvisable to run regression on the data as is. There are a couple of things you can try if you need to run regression:\n",
        "Give data that produces a large scatter less weight.\n",
        "Transform the Y variable to achieve homoscedasticity. For example, use the Box-Cox normality plot to transform the data.\n"
      ],
      "metadata": {
        "id": "DEdQ7L-cdBSx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Collinearity**\n",
        "\n",
        "Collinearity refers to the situation in which two or more predictor variables collinearity are closely related to one another. The presence of collinearity can pose problems in the regression context, since it can be difficult to separate out the individual effects of collinear variables on the response. It is possible for collinearity to exist between three or more variables even if no pair of variables has a particularly high correlation. We call this situation **multicollinearity**.\n",
        "\n"
      ],
      "metadata": {
        "id": "2OByd1KeM4qM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Variance inflation factor (VIF)**\n",
        "\n",
        "Instead of inspecting the correlation matrix, a better way to assess multicollinearity is to compute the variance inflation factor (VIF). Note that we ignore the intercept in this test.\n",
        "\n",
        "The smallest possible value for VIF is 1, which indicates the complete absence of collinearity. Typically in practice there is a small amount of collinearity among the predictors.\n",
        "\n",
        "As a rule of thumb, a VIF value that exceeds 5 indicates a problematic amount of collinearity and the parameter estimates will have large standard errors because of this."
      ],
      "metadata": {
        "id": "umh5ff4kMtVN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**VIF measures the ratio between the variance for a given regression coefficient with only that variable in the model versus the variance for a given regression coefficient with all variables in the model.**\n",
        "A VIF of 1 (the minimum possible VIF) means the tested predictor is not correlated with the other predictors.A VIF of 1 (the minimum possible VIF) means the tested predictor is not correlated with the other predictors."
      ],
      "metadata": {
        "id": "tW3OFS3Y1q3_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cls1.vif_table()"
      ],
      "metadata": {
        "id": "-wgeksAF7nCA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c832b7f8-2bd5-4cb3-ce2d-532cff8ff219"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Features  VIF Factor\n",
            "0  Intercept        1.00\n",
            "6     Volume        4.01\n",
            "5   AdjClose      388.60\n",
            "3        Low    37482.12\n",
            "1       Open    40591.97\n",
            "4      Close    46045.46\n",
            "2       High    57530.44\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ultimately, the presence of multicollinearity results in several problems:\n",
        "\n",
        "\n",
        "1.   The fitted regression coefficients (beta hat) will change substantially if one of the values of one of the x variables is changed only a bit.\n",
        "2.   The variance of the estimated coefficients will be inflated, which means that it will be hard to detect statistical significance. Furthermore, it’s possible that the F statistic is significant but the individual t statistics are not.\n",
        "3.   Ultimately, multicollinearity makes prediction less accurate. For a given model, the underlying assumption is that the relationships among the predicting variables, as well as their relationship with the target variable, will be the same. However, when multicollinearity is present, this is less likely to be the case.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Zy2rxuym0tfm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**There is a multicollinearity problem**"
      ],
      "metadata": {
        "id": "nqH7--wuOwmF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Correlation and forecasting\n"
      ],
      "metadata": {
        "id": "k_4SktcRRsDu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Forecasting with correlated predictors**\n",
        "\n",
        "When two or more predictors are highly correlated it is always challenging to accurately separate their individual effects. Having correlated predictors is not really a problem for forecasting, as we can still compute forecasts without needing to separate out the effects of the predictors. However, it becomes a problem with scenario forecasting as the scenarios should take account of the relationships between predictors. It is also a problem if some historical analysis of the contributions of various predictors is required.\n",
        "\n",
        "**Multicollinearity and forecasting**\n",
        "\n",
        "A closely related issue is multicollinearity, which occurs when similar information is provided by two or more of the predictor variables in a multiple regression. It can occur when two predictors are highly correlated with each other (that is, they have a correlation coefficient close to +1 or -1). In this case, knowing the value of one of the variables tells you a lot about the value of the other variable. Hence, they are providing similar information. For example, foot size can be used to predict height, but including the size of both left and right feet in the same model is not going to make the forecasts any better, although it won’t make them worse either.\n",
        "\n",
        "Multicollinearity can also occur when a linear combination of predictors is highly correlated with another linear combination of predictors. In this case, knowing the value of the first group of predictors tells you a lot about the value of the second group of predictors. Hence, they are providing similar information.\n",
        "\n",
        "An example of this problem is the dummy variable trap discussed in Section 5.4. Suppose you have quarterly data and use four dummy variables, d1, d2, d3 and d4. Then d4=1−d1−d2−d3, so there is perfect correlation between d4 and d1+d2+d3.\n",
        "In the case of perfect correlation (i.e., a correlation of +1 or -1, such as in the dummy variable trap), it is not possible to estimate the regression model.\n",
        "If there is high correlation (close to but not equal to +1 or -1), then the estimation of the regression coefficients is computationally difficult. In fact, some software (notably Microsoft Excel) may give highly inaccurate estimates of the coefficients. Most reputable statistical software will use algorithms to limit the effect of multicollinearity on the coefficient estimates, but you do need to be careful. The major software packages such as R, SPSS, SAS and Stata all use estimation algorithms to avoid the problem as much as possible.\n",
        "\n",
        "When multicollinearity is present, the uncertainty associated with individual regression coefficients will be large. This is because they are difficult to estimate. Consequently, statistical tests (e.g., t-tests) on regression coefficients are unreliable. (In forecasting we are rarely interested in such tests. Also, it will not be possible to make accurate statements about the contribution of each separate predictor to the forecast.\n",
        "**Forecasts will be unreliable if the values of the future predictors are outside the range of the historical values of the predictors**. For example, suppose you have fitted a regression model with predictors x1 and x2 which are highly correlated with each other, and suppose that the values of x1 in the fitting data ranged between 0 and 100. Then forecasts based on x1>100 or 0>x1 will be unreliable. **It is always a little dangerous when future values of the predictors lie much outside the historical range, but it is especially problematic when multicollinearity is present**.\n",
        "\n",
        "if you are not interested in the specific contributions of each predictor, and if the future values of your predictor variables are within their historical ranges, there is nothing to worry about — multicollinearity is not a problem except when there is perfect correlation.\n",
        "\n"
      ],
      "metadata": {
        "id": "-OI_0ZPy18Ov"
      }
    }
  ]
}